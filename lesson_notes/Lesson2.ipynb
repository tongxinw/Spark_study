{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Four key computer components:\n",
    "- CPU, the brain, CPU operation 0.4ns\n",
    "- memory (RAM), memory reference 100ns\n",
    "- storage, random read from SSD 16us\n",
    "- network, data from China to US 150 ms\n",
    "\n",
    "#### Details\n",
    "CPUs are fast, but memory is not. Thus, most time CPU will be IDLE to wait for datas to load.\n",
    "\n",
    "CPU, RAM, and SSD have improved along time, but network speed is still left behind. This means we nned to aim on reduce moving data from machine to machine using networks. \n",
    "\n",
    "![](img/key_ratios.png)\n",
    "\n",
    "If a dataset is larger than the size of your RAM, you might still be able to analyze the data on a single computer. By default, the Python pandas library will read in an entire dataset from disk into memory. If the dataset is larger than your computer's memory, the program won't work.\n",
    "\n",
    "However, the Python pandas library can read in a file in smaller chunks. Thus, if you were going to calculate summary statistics about the dataset such as a sum or count, you could read in a part of the dataset at a time and accumulate the sum or count.\n",
    "\n",
    "Example: \n",
    "```\n",
    "reader = pd.read_csv('tmp.sv', sep='|', chunksize=4)\n",
    "\n",
    "In [191]: reader\n",
    "Out[191]: <pandas.io.parsers.TextFileReader at 0x7f3d18adb350>\n",
    "\n",
    "In [192]: for chunk in reader:\n",
    "   .....:     print(chunk)\n",
    "```\n",
    "\n",
    "The difference between distributed computing and parallel computing\n",
    "![](img/distributed_comp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Reduce\n",
    "### Steps in Mapreduce\n",
    "- map: get (key, value) pairs\n",
    "- shuffle: same key files go to the same CPU/machine/cluster node\n",
    "- reduce: calculate\n",
    "\n",
    "### Spark\n",
    "Limitations: high latency in streaming compare to Flink and Storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
